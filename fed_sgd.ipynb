{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7058296b-3a28-43e5-8802-851d0a614862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import attacks\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from attacks import calculate_synthetic_random_baseline\n",
    "import torch\n",
    "from utils import Timer\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1730ef-553b-4a03-8f1a-489ef6c17fc6",
   "metadata": {},
   "source": [
    "## General results on FedSGD with known label (top halves of table 1 in the main paper, and tables 17-19 in the Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47300e31-2651-4a2e-a45a-49f592d7391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['ADULT', 'German', 'Lawschool', 'HealthHeritage']  # set to include only the datasets on which you have already obtained the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba3c51-e785-483d-a722-576198273198",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    46: 'TabLeak',\n",
    "    47: 'TabLeak (no pooling)',\n",
    "    4103: 'TabLeak (no softmax)',\n",
    "    0: 'Inverting Gradients',\n",
    "    1000: 'Deep Gradient Leakage'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1001096-6301-4b3c-928c-846b2f919a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "display_map = {\n",
    "    'mean': 0,\n",
    "    'std': 1,\n",
    "    'median': 2,\n",
    "    'min': 3,\n",
    "    'max': 4\n",
    "}\n",
    "training_epochs = {\n",
    "    0: 0\n",
    "}\n",
    "\n",
    "show_all_features = False\n",
    "display = 'mean'\n",
    "training_epochs_display = [0]\n",
    "training_epochs_to_display = {key: training_epochs[key] for key in training_epochs_display}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485880c1-64c5-411b-9c9a-8337224196be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_per_dataset = {}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    \n",
    "    # load random baseline\n",
    "    random_baseline = np.load(f'experiment_data/initial_experiments/random_inversion/{dataset_name}/random_baseline_{batch_sizes[-1]}_0.319_all_empirical.npy')\n",
    "    \n",
    "    # load all available experiments\n",
    "    experiments_data = {}\n",
    "    for experiment_num in experiments.keys():\n",
    "        base_path = f'experiment_data/large_scale_experiments/{dataset_name}/experiment_{experiment_num}'\n",
    "        if experiment_num in [46, 4103]:\n",
    "            specific_file_path = base_path + f'/inversion_data_all_{experiment_num}_{dataset_name}_50_30_1500_{batch_sizes[-1]}_0.319_42.npy'\n",
    "        else:\n",
    "            specific_file_path = base_path + f'/inversion_data_all_{experiment_num}_{dataset_name}_50_1_1500_{batch_sizes[-1]}_0.319_42.npy'\n",
    "        if os.path.isfile(specific_file_path):\n",
    "            experiments_data[experiment_num] = np.load(specific_file_path).astype(np.float32)\n",
    "    \n",
    "    dataframe_of_dataset = pd.DataFrame()\n",
    "    dataframe_of_dataset['Batch Size'] = batch_sizes\n",
    "    for experiment_num, experiment_data in experiments_data.items():\n",
    "        formatted_experiment_col = []\n",
    "        random_baseline_col = []\n",
    "        for l, batch_size in enumerate(batch_sizes):\n",
    "            formatted_experiment_col.append((np.around(100-100*experiments_data[experiment_num][0, l, 0, display_map[display]], 1), np.around(100*experiments_data[experiment_num][0, l, 0, 1], 1)))\n",
    "            random_baseline_col.append((np.around(100 - 100*random_baseline[l, 0, display_map[display]], 1), np.around(100*random_baseline[l, 0, 1], 1)))\n",
    "        dataframe_of_dataset[experiments[experiment_num]] = formatted_experiment_col\n",
    "    dataframe_of_dataset['Random Baseline'] = random_baseline_col\n",
    "    dataframes_per_dataset[dataset_name] = dataframe_of_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1f8567-09a1-4808-bd08-76ac94725c6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffb1d1-a706-43a8-a583-25389ac1dec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_per_dataset['ADULT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46613b-34bd-4944-9628-97bf37864349",
   "metadata": {},
   "source": [
    "### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be4a75-bccc-462b-b433-7934b6849677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_per_dataset['German']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7189111-66e2-40bf-aef4-b2fdad0f6e67",
   "metadata": {},
   "source": [
    "### Lawschool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557ca27-50df-43ef-af55-91a239b6b969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_per_dataset['Lawschool']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e5b53-4ecc-46cb-9ced-7b632539421b",
   "metadata": {},
   "source": [
    "### Health Heritage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50913783-1635-42c5-ae58-ecfdd2556780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_per_dataset['HealthHeritage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68938453-21f0-44b9-918a-6687a05e628e",
   "metadata": {},
   "source": [
    "## General results on FedSGD with unknown label (bottom halves of table 1 in the main paper, and tables 17-19 in the Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f36a5-7bed-4ba9-b870-75f7f5f3a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['ADULT', 'German', 'Lawschool', 'HealthHeritage']  # set to include only the datasets on which you have already obtained the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b046dd2-38b1-4542-8947-eecaf5f2862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    946: 'TabLeak',\n",
    "    947: 'TabLeak (no pooling)',\n",
    "    94103: 'TabLeak (no softmax)',\n",
    "    90: 'Inverting Gradients',\n",
    "    91000: 'Deep Gradient Leakage'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c528df-eb7a-49f3-9a59-981f0f143da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "display_map = {\n",
    "    'mean': 0,\n",
    "    'std': 1,\n",
    "    'median': 2,\n",
    "    'min': 3,\n",
    "    'max': 4\n",
    "}\n",
    "training_epochs = {\n",
    "    0: 0\n",
    "}\n",
    "\n",
    "show_all_features = False\n",
    "display = 'mean'\n",
    "training_epochs_display = [0]\n",
    "training_epochs_to_display = {key: training_epochs[key] for key in training_epochs_display}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c21155-70a5-4ea0-a184-d6c86e0e1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_per_dataset = {}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    \n",
    "    # load random baseline\n",
    "    random_baseline = np.load(f'experiment_data/initial_experiments/random_inversion/{dataset_name}/random_baseline_{batch_sizes[-1]}_0.319_all_empirical.npy')\n",
    "    \n",
    "    # load all available experiments\n",
    "    experiments_data = {}\n",
    "    for experiment_num in experiments.keys():\n",
    "        base_path = f'experiment_data/large_scale_experiments/{dataset_name}/experiment_{experiment_num}'\n",
    "        if experiment_num in [946, 94103]:\n",
    "            specific_file_path = base_path + f'/inversion_data_all_{experiment_num}_{dataset_name}_50_30_1500_{batch_sizes[-1]}_0.319_42.npy'\n",
    "        else:\n",
    "            specific_file_path = base_path + f'/inversion_data_all_{experiment_num}_{dataset_name}_50_1_1500_{batch_sizes[-1]}_0.319_42.npy'\n",
    "        if os.path.isfile(specific_file_path):\n",
    "            experiments_data[experiment_num] = np.load(specific_file_path).astype(np.float32)\n",
    "    \n",
    "    dataframe_of_dataset = pd.DataFrame()\n",
    "    dataframe_of_dataset['Batch Size'] = batch_sizes\n",
    "    for experiment_num, experiment_data in experiments_data.items():\n",
    "        formatted_experiment_col = []\n",
    "        random_baseline_col = []\n",
    "        for l, batch_size in enumerate(batch_sizes):\n",
    "            formatted_experiment_col.append((np.around(100-100*experiments_data[experiment_num][0, l, 0, display_map[display]], 1), np.around(100*experiments_data[experiment_num][0, l, 0, 1], 1)))\n",
    "            random_baseline_col.append((np.around(100 - 100*random_baseline[l, 0, display_map[display]], 1), np.around(100*random_baseline[l, 0, 1], 1)))\n",
    "        dataframe_of_dataset[experiments[experiment_num]] = formatted_experiment_col\n",
    "    dataframe_of_dataset['Random Baseline'] = random_baseline_col\n",
    "    dataframes_per_dataset[dataset_name] = dataframe_of_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ce266-e29b-4139-9760-bf47d261e96f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21eccbd-5764-4a03-9682-fbe8f613b239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_per_dataset['ADULT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7969ce3-be48-46b4-b77a-0165cebf14df",
   "metadata": {},
   "source": [
    "### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e3c0f-a7cc-48b9-9d06-a3fabb7f7b46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_per_dataset['German']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a0ace-1581-44ef-8558-f03c15214db2",
   "metadata": {},
   "source": [
    "### Lawschool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467133f-7572-4e8e-81f7-231ca8b09bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_per_dataset['Lawschool']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e424cfc-cd5a-4c61-9ad4-15db6ab2ddcf",
   "metadata": {},
   "source": [
    "### Health Heritage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d6947-6718-4acb-8ddb-8620a16e957d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_per_dataset['HealthHeritage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85cdff5-4041-4bee-8d6f-e61061882b66",
   "metadata": {},
   "source": [
    "## Categorical vs. Continous feature reconstruction errors (Figures 4 and 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b4b1d-5abb-4edb-ae10-3ccfaf6f7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    0: 'Inverting Gradients, \\n',\n",
    "    46: 'TabLeak, \\n'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902878e1-6bdb-408b-a036-76fc087a15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "display_map = {\n",
    "    'mean': 0,\n",
    "    'std': 1,\n",
    "    'median': 2,\n",
    "    'min': 3,\n",
    "    'max': 4\n",
    "}\n",
    "training_epochs = {\n",
    "    0: 0,\n",
    "    100: 1\n",
    "}\n",
    "\n",
    "show_all_features = False\n",
    "display = 'mean'\n",
    "training_epochs_display = [0]\n",
    "training_epochs_to_display = {key: training_epochs[key] for key in training_epochs_display}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d92cd-a42d-4d7d-8309-c8be6cd58886",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_colors = {\n",
    "    0: 'cornflowerblue',\n",
    "    46: 'indigo'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ca092-96df-491b-ac40-46a3d710ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    error_types = ['disc', 'cont']\n",
    "    \n",
    "    # load all available experiments\n",
    "    experiments_data = {}\n",
    "    for experiment_num in experiments.keys():\n",
    "        base_path = f'experiment_data/large_scale_experiments/{dataset_name}/experiment_{experiment_num}'\n",
    "        if experiment_num == 46:\n",
    "            specific_file_path = base_path + f'/inversion_data_all_{experiment_num}_{dataset_name}_50_30_1500_{batch_sizes[-1]}_0.319_42.npy'\n",
    "        else:\n",
    "            specific_file_path = base_path + f'/inversion_data_all_{experiment_num}_{dataset_name}_50_1_1500_{batch_sizes[-1]}_0.319_42.npy'\n",
    "        if os.path.isfile(specific_file_path):\n",
    "            experiments_data[experiment_num] = np.load(specific_file_path).astype(np.float32)\n",
    "            \n",
    "    plt.figure(figsize=(11, 10))\n",
    "    ax = plt.axes()\n",
    "    ax.set_facecolor('white')\n",
    "    ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "    for i, error_type in enumerate(error_types):\n",
    "        i = i + 1\n",
    "        \n",
    "        for experiment_num, experiment_data in experiments_data.items():\n",
    "            for epoch_num, epoch_indx in training_epochs_to_display.items():\n",
    "                if error_type == 'disc':\n",
    "                    label_extension = 'discrete'\n",
    "                else:\n",
    "                    label_extension = 'continuous'\n",
    "                plt.plot(batch_sizes, 1 - experiments_data[experiment_num][epoch_indx, :, i, display_map[display]], '--', marker=f'${error_type[0].capitalize()}$', c=experiment_colors[experiment_num], markersize=20, label=experiments[experiment_num] + label_extension)\n",
    "                if display in ['mean', 'median']:\n",
    "                    plt.fill_between(batch_sizes, 1 - experiments_data[experiment_num][epoch_indx, :, i, display_map[display]] - experiments_data[experiment_num][epoch_indx, :, i, 1], \n",
    "                                     np.minimum(1 - experiments_data[experiment_num][epoch_indx, :, i, display_map[display]] + experiments_data[experiment_num][epoch_indx, :, i, 1], np.ones(len(batch_sizes))), \n",
    "                                     color=experiment_colors[experiment_num], alpha=0.05)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Batchsize (log scale)', fontsize=30, labelpad=15)\n",
    "    plt.xticks(batch_sizes, batch_sizes, fontsize=30)\n",
    "    plt.ylabel('Reconstruction Accuracy [%]', fontsize=30, labelpad=15)\n",
    "    plt.yticks(0.2 + 0.1 * np.arange(9), 20 + 10 * np.arange(9), fontsize=30)\n",
    "    loc = 'lower right' if error_type != 'cont' else 'upper right'\n",
    "    ax.legend(fancybox=True, fontsize=30, loc=(.03, .04), framealpha=0.5)\n",
    "    plt.title(f'{dataset_name}', fontsize=30)\n",
    "    plt.grid(True, alpha=.3)\n",
    "    plt.box(False)\n",
    "    plt.ylim([0.18, 1.02])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    print('\\n', '\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1168773-40e2-4554-9511-a10e14465023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaf5217cd85eca15e4c4451d1b8557912f40370a12c28b233288a3f62546396d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
